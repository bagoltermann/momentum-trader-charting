# Session Notes - 2026-02-04

## Status
Found and fixed the TRUE root cause of recurring backend event loop freezes (Fix #23). Previous fixes #22 and #22b were misdiagnoses.

## Session Overview
1. **Morning**: Diagnose third backend freeze (polling-based fix #22b also failed)
2. **Morning**: Identify true root cause: `asyncio.Queue.put_nowait()` called from QuoteRelay's SocketIO thread (not thread-safe)
3. **Morning**: Fix #23 - Use `loop.call_soon_threadsafe()` for cross-thread queue access
4. **Morning**: Fix blocking file I/O in `get_trade_history()` route

---

## Work Completed

### 1. Fix #23: asyncio.Queue Cross-Thread Corruption from QuoteRelay

**Problem**: Backend kept freezing after 30-90 minutes despite two previous fix attempts (#22 and #22b). Third freeze occurred at 07:49:45 on 2026-02-04.

**Key Evidence from `logs/backend.log`**:
```
07:49:30 [INFO] [HEARTBEAT] #25 - Event loop alive, 11 tasks
07:49:43 [INFO] [WS-QUOTES] Subscribe: ['TOYO']
07:49:45 [INFO] [Route #71] GET /candles/PSIG completed with 1 candles
-- SILENCE -- (heartbeat #26 at 07:50:00 never fires)
```

**Key Evidence from `logs/watchdog.log`**:
```
2026-02-04 07:51:15 [ERROR] [WATCHDOG] Event loop appears FROZEN - no heartbeat for 105s
2026-02-04 07:52:00 [ERROR] [WATCHDOG] Event loop appears FROZEN - no heartbeat for 150s
```

**Breakthrough**: The last operations before the freeze were ALL **cache hits** — NO thread pool requests were in flight. This proves the Schwab API thread pool (`make_api_request`) was NOT the cause.

**Root Cause**: `asyncio.Queue.put_nowait()` is NOT thread-safe ([Python docs](https://docs.python.org/3/library/asyncio-queue.html)). The QuoteRelay's SocketIO thread was calling it directly:

```python
# BEFORE (BROKEN) - called from QuoteRelay's SocketIO thread
def on_quote(data):
    queue.put_nowait(data)  # NOT thread-safe! Corrupts internal deque
```

With 10+ subscribed symbols receiving continuous quote updates, the SocketIO thread and event loop thread were both accessing the queue's internal `collections.deque` without synchronization, eventually corrupting it and deadlocking the event loop.

**Fix**:
```python
# AFTER (FIXED) - schedule on event loop thread via call_soon_threadsafe
loop = asyncio.get_event_loop()

def on_quote(data):
    loop.call_soon_threadsafe(queue.put_nowait, data)

def on_status(data):
    loop.call_soon_threadsafe(queue.put_nowait, data)
```

**File Modified**: `backend/api/routes.py:281-294`

---

### 2. Fix Blocking File I/O in get_trade_history()

**Problem**: `get_trade_history()` route performed synchronous file reads inside an async handler, blocking the event loop during JSONL file parsing.

**Fix**: Wrapped file read in `asyncio.to_thread()`:
```python
def _read_trades():
    trades = []
    with open(outcomes_path, 'r') as f:
        for line in f:
            ...
    return trades

trades = await asyncio.to_thread(_read_trades)
```

**File Modified**: `backend/api/routes.py:152-170`

---

### 3. Why Previous Fixes Were Wrong

| Fix | Theory | Why It Failed |
|-----|--------|---------------|
| #22 (dict return) | httpx.Response socket objects crossing thread boundary caused deadlock | Third freeze had NO API requests in flight |
| #22b (polling) | `call_soon_threadsafe()` in `asyncio.to_thread()` deadlocking WindowsSelectorEventLoop | Same — freeze happened during cache-only operation |

Both fixes addressed `make_api_request()`, but the actual cross-thread corruption was in the **WebSocket quote relay path**. The polling-based approach and dict returns are still good defensive measures, but they weren't fixing the real bug.

---

## Testing Checklist

- [ ] Restart charting app and verify backend starts normally
- [ ] Subscribe to multiple symbols (10+) and monitor for 1+ hour
- [ ] Check `logs/watchdog.log` for any freeze warnings
- [ ] Verify quote streaming works (real-time price updates in charts)
- [ ] Verify trade history loads without blocking other operations

## Files Modified

| File | Changes |
|------|---------|
| `backend/api/routes.py` | Fix #23: `call_soon_threadsafe()` for cross-thread queue access; `asyncio.to_thread()` for trade history file I/O |
| `docs/session-notes/2026-01-27-chart-not-displaying-troubleshooting.md` | Added failure mode #23, updated #22 with misdiagnosis note |

## Key Takeaways

1. **`asyncio.Queue` is NOT thread-safe**: Python docs are explicit about this. Any cross-thread access must use `loop.call_soon_threadsafe()` or a thread-safe queue like `janus`.
2. **Log analysis is everything**: The breakthrough came from noticing the freeze occurred with NO API requests in flight — only cache hits and quote relay activity. This eliminated the thread pool hypothesis entirely.
3. **Watchdog thread worked**: The independent watchdog (writing directly to `logs/watchdog.log`) successfully detected and logged the freeze, confirming it was a real event loop deadlock.
4. **Misdiagnosis is expensive**: Two previous fix attempts (#22, #22b) modified the wrong code path. Always verify the hypothesis matches the evidence before implementing a fix.

---

## Afternoon Session: Fix #23 Didn't Resolve Freeze

### 4. Fourth Freeze — Fix #23 Was Deployed

**Problem**: Backend froze again at 11:45:36 with fix #23 (call_soon_threadsafe) deployed. Ran for 3+ hours before freezing.

**Evidence from `logs/backend.log`**:
```
11:45:14 [INFO] [HEARTBEAT] #368 - Event loop alive, 11 tasks
11:45:35 [INFO] make_api_request: Starting request to .../pricehistory
11:45:36 [INFO] HTTP Request: GET .../pricehistory?symbol=ELPW... "HTTP/1.1 200 OK"
-- SILENCE -- (no "Got response status", no heartbeat #369)
11:52:20 [INFO] Runners reloaded  (file watcher thread still running)
```

**Key Observation**: This time the freeze occurred during an **active API request** (ELPW), not during cache-only operation. The httpx thread logged "200 OK" but `make_api_request: Got response status` never appeared — meaning the event loop's `asyncio.sleep(0.05)` poll never completed.

**Analysis**: With the polling-based code, `make_api_request` does `await asyncio.sleep(0.05)` in a loop. If the event loop itself is frozen, that sleep can't return. The asyncio.Queue fix (#23) addressed one cross-thread issue, but there may be additional causes.

**New Theory**: Logging module `threading.RLock` contention. All loggers share a single `FileHandler` via `logging.basicConfig()`. When the event loop thread and httpx thread pool worker both call `_logger.info()` simultaneously, they contend for the same lock. If file I/O stalls (Windows Defender, disk flush), the event loop thread blocks while holding or waiting for the lock.

---

### 5. Added Diagnostic Instrumentation

**Thread Stack Dump on Freeze** (`main.py:92-105`):
```python
if not _stack_dumped:
    _stack_dumped = True
    f.write(f"{ts} [ERROR] [WATCHDOG] === THREAD STACK DUMP ===\n")
    for thread_id, frame in _sys._current_frames().items():
        thread_name = "Unknown"
        for t in threading.enumerate():
            if t.ident == thread_id:
                thread_name = t.name
                break
        f.write(f"\n--- Thread {thread_id} ({thread_name}) ---\n")
        f.write("".join(traceback.format_stack(frame)))
```

When the watchdog detects a freeze, it dumps ALL thread stack traces to `logs/watchdog.log`. This will show exactly what the event loop thread is stuck on.

**asyncio Debug Mode** (`main.py:128-129`):
```python
loop.set_debug(True)
loop.slow_callback_duration = 1.0
```

Logs any callback taking >1s before the actual freeze.

**Suppressed httpx Internal Logging** (`schwab_client.py:38-40`):
```python
logging.getLogger('httpx').setLevel(logging.WARNING)
logging.getLogger('httpcore').setLevel(logging.WARNING)
```

Reduces lock contention between httpx thread pool workers and the event loop thread on the FileHandler's `threading.RLock`.

**Faster Watchdog** (`main.py:84-86`):
- Checks every 15s (was 45s)
- Freeze detection at 60s (was 90s)

---

## Updated Testing Checklist

- [ ] Restart charting app with diagnostic instrumentation
- [ ] Monitor `logs/watchdog.log` for stack dump on next freeze
- [ ] Analyze stack dump to identify exact blocking operation
- [ ] Check for slow callback warnings in `logs/backend.log`

## Files Modified (Afternoon)

| File | Changes |
|------|---------|
| `backend/main.py` | Thread stack dump in watchdog, asyncio debug mode, faster watchdog checks |
| `backend/services/schwab_client.py` | Suppressed httpx/httpcore logging to reduce lock contention |

## Key Takeaways (Updated)

1. **`asyncio.Queue` fix was correct but incomplete**: Fix #23 addressed a real thread-safety bug, but the backend still froze — there are multiple contributing factors.
2. **Logging lock contention is a prime suspect**: All loggers share one FileHandler with one `threading.RLock`. When httpx logs from thread pool workers, they compete with the event loop thread for the same lock.
3. **Stack dumps are essential**: Without knowing exactly what the event loop thread is stuck on, we're guessing. The new watchdog will capture this on the next freeze.
4. **Windows + asyncio + file I/O**: File operations (logging flush, disk writes) can stall unpredictably on Windows due to antivirus, Windows Defender, or disk caching.

## Next Steps

1. **Wait for next freeze** and capture stack dump from `logs/watchdog.log`
2. **Analyze stack dump** to determine exact blocking operation
3. **Implement targeted fix** based on findings (may need async logging handler, or separate log files per thread)

---

**Session Duration**: Morning ~30 minutes + Afternoon ~45 minutes
